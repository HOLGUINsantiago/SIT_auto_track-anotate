{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d78ba34",
   "metadata": {},
   "source": [
    "# SIT automatic behaviour detection pipeline\n",
    "## By Santiago Holguin Urbano\n",
    "\n",
    "This pipeline allows to identify different behaviours of two B6 mice. The detected behaviuors are : Contact by host, Contact by visitor, Follow by host, Follow by visitor,Paw control (host), Rearing (host), and Grooming (host).\n",
    "\n",
    "This pipeline can be used with pretrained models on videos at the following format : \n",
    "[image-2.png](attachment:image-2.png)\n",
    "\n",
    "But the different tools used can be adapated for different format and different behaviours. If you're working with CD1 mice or with a very different environment, we suggest you to retrain all the models by following each method documentation. You need at least 600 annotated frames for tracking, and at least 9k annotated frames per beahaviour for behaviuor estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14bd2f7",
   "metadata": {},
   "source": [
    "## 1. Tracking videos (use Sleap kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7939471f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando: SIT1-JNG-77-4-2025-04-15 09-04-17.mp4\n",
      "Comando a ejecutar:\n",
      "conda run -n sleap sleap-track -m \"SLEAP_track\\models\\250702_114533.centroid.n=765\" -m \"SLEAP_track\\models\\250702_132640.centered_instance.n=765\" --tracking.tracker flow --tracking.similarity centroid --tracking.match hungarian --tracking.max_tracks 2 -n 2 -o \"tracked_videos\" \"for_tracking\\SIT1-JNG-77-4-2025-04-15 09-04-17.mp4\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# === Configuraci√≥n de variables ===\n",
    "MODEL_centroid_PATH = r\"SLEAP_track\\models\\250702_114533.centroid.n=765\"\n",
    "MODEL_centered_instance_PATH = r\"SLEAP_track\\models\\250702_132640.centered_instance.n=765\"\n",
    "\n",
    "VIDEOS_FOLDER = Path(r\"for_tracking\")\n",
    "OUTPUT_FOLDER = Path(r\"tracked_videos\")\n",
    "MAX_INSTANCES = 2\n",
    "MAX_TRACKS = 2\n",
    "\n",
    "# Crear carpeta de salida si no existe\n",
    "OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Procesar cada video individualmente ===\n",
    "for video_file in VIDEOS_FOLDER.glob(\"*.mp4\"):\n",
    "    print(f\"\\nProcesando: {video_file.name}\")\n",
    "\n",
    "    command = (\n",
    "        f'conda run -n sleap '\n",
    "        f'sleap-track '\n",
    "        f'-m \"{MODEL_centroid_PATH}\" '\n",
    "        f'-m \"{MODEL_centered_instance_PATH}\" '\n",
    "        f'--tracking.tracker flow '\n",
    "        f'--tracking.similarity centroid '\n",
    "        f'--tracking.match hungarian '\n",
    "        f'--tracking.max_tracks {MAX_TRACKS} '\n",
    "        f'-n {MAX_INSTANCES} '\n",
    "        f'-o \"{OUTPUT_FOLDER}\" '\n",
    "        f'\"{video_file}\"'\n",
    "    )\n",
    "\n",
    "    print(\"Comando a ejecutar:\")\n",
    "    print(command)\n",
    "\n",
    "    os.system(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcbb1a3",
   "metadata": {},
   "source": [
    "# 2. Correcting tracking errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f610c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda run -n sleap_andGUI python correcting_sleap_errors.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88325f09",
   "metadata": {},
   "source": [
    "# 3. Adding videos to  (use Deg kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f136925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from deepethogram import projects\n",
    "import pandas as pd\n",
    "\n",
    "def a√±adir_videos_sin_reparar(project_config_path, carpeta_videos, modo='copy', extensiones=None, csv_filtro_path=None):\n",
    "    if extensiones is None:\n",
    "        extensiones = ['.mp4', '.avi', '.mov', '.mkv', '.wmv']\n",
    "    \n",
    "    # Cargar proyecto\n",
    "    proyecto = projects.load_config(project_config_path)\n",
    "    \n",
    "    # Cargar filtro CSV si se da\n",
    "    nombres_permitidos = None\n",
    "    if csv_filtro_path and os.path.exists(csv_filtro_path):\n",
    "        df_filtro = pd.read_csv(csv_filtro_path)\n",
    "        nombres_permitidos = set(os.path.splitext(v)[0] for v in df_filtro['video_name'].values)\n",
    "        print(f\"[üîé] Usando filtro CSV con {len(nombres_permitidos)} videos permitidos.\")\n",
    "    \n",
    "    # Listar videos v√°lidos\n",
    "    videos_para_a√±adir = []\n",
    "    for archivo in os.listdir(carpeta_videos):\n",
    "        ruta_completa = os.path.join(carpeta_videos, archivo)\n",
    "        if os.path.isfile(ruta_completa) and os.path.splitext(archivo)[1].lower() in extensiones:\n",
    "            nombre_sin_ext = os.path.splitext(archivo)[0].replace(\" \", \"\")\n",
    "            if nombres_permitidos is None or nombre_sin_ext in nombres_permitidos:\n",
    "                videos_para_a√±adir.append(ruta_completa)\n",
    "    \n",
    "    print(f\"[üîç] Encontrados {len(videos_para_a√±adir)} videos para a√±adir.\")\n",
    "    \n",
    "    # A√±adir videos al proyecto\n",
    "    cont = 0\n",
    "    for video_path in videos_para_a√±adir:\n",
    "        try:\n",
    "            nueva_ruta = projects.add_video_to_project(proyecto, video_path, mode=modo)\n",
    "            cont += 1\n",
    "            print(f\"[+] A√±adido: {video_path} ‚Üí {nueva_ruta} ({cont}/{len(videos_para_a√±adir)})\")\n",
    "        except Exception as e:\n",
    "            print(f\"[‚úó] Error a√±adiendo {video_path}: {e}\")\n",
    "\n",
    "# === CONFIGURACI√ìN ===\n",
    "config_path = r\"D:\\SIT_auto\\SIT_deepethogram\\project_config.yaml\"\n",
    "carpeta_videos = r\"corrected_videos\"\n",
    "\n",
    "a√±adir_videos_sin_reparar(config_path, carpeta_videos=carpeta_videos, modo='copy', csv_filtro_path=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd32104",
   "metadata": {},
   "source": [
    "# 4. Adding annotations\n",
    "You can either open and manually annotate videos in DeepEthogram, or you can transform solomon csv annotations on DeG compatible csv files by using this script : [transform](training_data_conversion\\LBNtrasnformCSV.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a80847",
   "metadata": {},
   "source": [
    "# 5. Train DeG models (see [deg documentation](https://github.com/jbohnslav/deepethogram/blob/master/docs/getting_started.md))\n",
    "Once you've annotate multiple videos you will be able to train a model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robust_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
